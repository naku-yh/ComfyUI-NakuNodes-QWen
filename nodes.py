import torch
import comfy.samplers
import comfy.model_management
import comfy.controlnet
import comfy.cldm.control_types
from comfy.cldm.control_types import UNION_CONTROLNET_TYPES
import folder_paths
from .cache import remove_cache
import numpy as np
from PIL import Image
import os
from .utils import *


class QwenImageIntegratedKSampler:

    def __init__(self):
        self.device = comfy.model_management.intermediate_device()

    @classmethod
    def INPUT_TYPES(s):
        generation_mode = ['æ–‡ç”Ÿå›¾', 'å›¾åƒç¼–è¾‘æ¨¡å¼']
        return {
            "required": {
                "model": ("MODEL", {"tooltip": "æ¨¡å‹ - æ‰©æ•£æ¨¡å‹è¾“å…¥ï¼Œç”¨ä½œå›¾åƒç”Ÿæˆçš„æ ¸å¿ƒæ¨¡å‹"}),
                "clip": ("CLIP", {"tooltip": "CLIP - CLIPæ¨¡å‹ï¼Œç”¨äºæ–‡æœ¬ç¼–ç å’Œæ¡ä»¶ç”Ÿæˆ"}),
                "vae": ("VAE", {"tooltip": "VAE - VAEæ¨¡å‹è¾“å…¥ï¼Œç”¨äºå°†æ½œç©ºé—´è§£ç ä¸ºæœ€ç»ˆå¯è§å›¾åƒ"}),
                "positive_prompt": ("STRING", {"multiline": True, "dynamicPrompts": True, "placeholder": "æ­£å‘æç¤ºè¯", "tooltip": "æ­£å‘æç¤º - æè¿°æœŸæœ›å›¾åƒå…ƒç´¢çš„æ–‡æœ¬æç¤º"}),
                "negative_prompt": ("STRING", {"multiline": True, "dynamicPrompts": True, "placeholder": "è´Ÿå‘æç¤ºè¯", "tooltip": "è´Ÿå‘æç¤º - æè¿°è¦é¿å…çš„å›¾åƒå…ƒç´ çš„æ–‡æœ¬æç¤º"}),
                "generation_mode": (generation_mode, {"tooltip": "ç”Ÿæˆæ¨¡å¼ - é€‰æ‹©æ–‡ç”Ÿå›¾æˆ–å›¾ç”Ÿå›¾æ¨¡å¼"}),
                "batch_size": ("INT", {"default": 1, "min": 1, "max": 10, "tooltip": "æ‰¹æ¬¡æ•°é‡ - ç”Ÿæˆå›¾åƒçš„æ•°é‡"}),
                "width": ("INT", {"default": 0, "min": 0, "max": 16384, "step": 8, "tooltip": "å®½åº¦(æ–‡ç”Ÿå›¾-å¿…å¡«ï¼Œå›¾ç”Ÿå›¾-å¡«å†™ç¼©æ”¾/å¡«0ä¸ç¼©æ”¾)"}),
                "height": ("INT", {"default": 0, "min": 0, "max": 16384, "step": 8, "tooltip": "é«˜åº¦(æ–‡ç”Ÿå›¾-å¿…å¡«ï¼Œå›¾ç”Ÿå›¾-å¡«å†™ç¼©æ”¾/å¡«0ä¸ç¼©æ”¾)"}),
                "seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff, "control_after_generate": True, "tooltip": "ç”Ÿæˆå™ªæ³¢çš„éšæœºç§ã€‚"}),
                "steps": ("INT", {"default": 4, "min": 1, "max": 10000, "tooltip": "é™å™ªçš„æ­¥æ•°ã€‚"}),
                "cfg": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step":0.1, "round": 0.01, "tooltip": "CFG - ç”¨äºå¹³è¡¡éšæœºæ€§å’Œæç¤ºè¯æœä»æ€§ã€‚æé«˜è¯¥å€¼ä¼šä½¿ç»“æœæ›´åŠ ç¬¦åˆæç¤ºè¯ï¼Œä½†è¿‡é«˜ä¼šå¯¼è‡´å›¾åƒè´¨é‡ä¸‹é™ã€‚"}),
                "sampler_name": (comfy.samplers.KSampler.SAMPLERS, {"default": "euler", "tooltip": "é‡‡æ ·å™¨ - é‡‡æ ·ç®—æ³•ï¼Œä¼šå½±å“ç»“æœè´¨é‡ã€ç”Ÿæˆé€Ÿåº¦ã€é£æ ¼æ ·å¼ã€‚"}),
                "scheduler": (comfy.samplers.KSampler.SCHEDULERS, {"default": "simple", "tooltip": "è°ƒåº¦å™¨ - æ§åˆ¶é€æ¸ç§»é™¤å™ªæ³¢çš„æ–¹æ³•ã€‚"}),
                "denoise": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "é™å™ªçš„å¼ºåº¦ï¼Œé™ä½è¯¥å€¼ä¼šä¿ç•™åŸå›¾çš„å¤§éƒ¨åˆ†å†…å®¹ä»è€Œå®ç°å›¾ç”Ÿå›¾ã€‚"}),
            },
            "optional": {
                "image1": ("IMAGE", {"tooltip": "å›¾åƒ1ï¼ˆä¸»å›¾ï¼‰ - å‚è€ƒå›¾åƒ1ï¼ˆä¸»å›¾ï¼‰ï¼Œç”¨äºæ¡ä»¶ç”Ÿæˆå’Œæ½œç©ºé—´ç¼–ç ã€‚å¦‚æœä¸ä¼ å…¥ï¼Œåˆ™æ–‡ç”Ÿå›¾ã€‚"}),
                "image2": ("IMAGE", {"tooltip": "å›¾åƒ2 - å‚è€ƒå›¾åƒ2ï¼Œç”¨äºæ¡ä»¶ç”Ÿæˆå’Œæ½œç©ºé—´ç¼–ç "}),
                "image3": ("IMAGE", {"tooltip": "å›¾åƒ3 - å‚è€ƒå›¾åƒ3ï¼Œç”¨äºæ¡ä»¶ç”Ÿæˆå’Œæ½œç©ºé—´ç¼–ç "}),
                "image4": ("IMAGE", {"tooltip": "å›¾åƒ4 - å‚è€ƒå›¾åƒ4ï¼Œç”¨äºæ¡ä»¶ç”Ÿæˆå’Œæ½œç©ºé—´ç¼–ç "}),
                "image5": ("IMAGE", {"tooltip": "å›¾åƒ5 - å‚è€ƒå›¾åƒ5ï¼Œç”¨äºæ¡ä»¶ç”Ÿæˆå’Œæ½œç©ºé—´ç¼–ç "}),
                "latent": ("LATENT", {"tooltip": "Latent - æ–‡ç”Ÿå›¾ã€å›¾ç”Ÿå›¾ï¼ˆä¼ å…¥äº†ä¸»å›¾ï¼‰å¯ä¸ä¼ ï¼Œè‡ªåŠ¨åˆ›å»ºï¼Œå¦‚éœ€ä½¿ç”¨ControlNetç­‰å¯è‡ªè¡Œä¼ å…¥"}),
                "controlnet_data": ("CONTROL_NET_DATA", {"tooltip": "ControlNet æ•°æ®ï¼ˆå¯é€‰ï¼‰ - è¾“å…¥ ControlNet é›†æˆåŠ è½½å™¨è¾“å‡ºçš„æ•°æ®åŒ…ï¼Œç›´æ¥åº”ç”¨ ControlNet æ§åˆ¶"}),
                "auraflow_shift": ("FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.01, "tooltip": "AuraFlowç§»ä½ - é‡‡æ ·ç®—æ³•ï¼ˆAuraFlowï¼‰ ç§»ä½Shiftå‚æ•°ï¼Œå½±å“é€Ÿåº¦å’Œè´¨é‡ (0-100)"}),
                "cfg_norm_strength": ("FLOAT", {"default": 1, "min": 0.0, "max": 100.0, "step": 0.01, "tooltip": "CFGNormå¼ºåº¦ - CFGæ ‡å‡†åŒ–å¼ºåº¦ï¼ŒåŠ¨æ€è°ƒæ•´CFGæŒ‡å¯¼å¼ºåº¦ (0-100)"}),
                "enable_clean_gpu_memory": ("BOOLEAN", {"default": False, "tooltip": "æ¸…ç†æ˜¾å­˜å ç”¨ - åœ¨é‡‡æ ·/è§£ç å‰åæ¸…ç†æ˜¾å­˜å ç”¨ï¼Œä»¥é‡Šæ”¾èµ„æºç»™å…¶ä»–åº”ç”¨"}),
                "enable_clean_cpu_memory_after_finish": ("BOOLEAN", {"default": False, "tooltip": "å®Œæˆåæ¸…ç†å†…å­˜ - ç”Ÿæˆå®Œæˆåæ¸…ç†CPUå†…å­˜"}),
                "enable_sound_notification": ("BOOLEAN", {"default": False, "tooltip": "å®Œæˆåæ’­æ”¾å£°éŸ³ - è§£ç å®Œæˆåæ’­æ”¾é€šçŸ¥å£°éŸ³ä»¥æé†’ç”¨æˆ·"}),
                "auto_save_output_folder": ("STRING", {"default": "", "tooltip": "è‡ªåŠ¨ä¿å­˜è¾“å‡ºæ–‡ä»¶å¤¹(ç•™ç©ºä¸è‡ªåŠ¨ä¿å­˜) - ç•™ç©ºåˆ™ä¸æ‰§è¡Œä¿å­˜"}),
                "output_filename_prefix": ("STRING", {"default": "auto_save", "tooltip": "è¾“å‡ºæ–‡ä»¶åå‰ç¼€ - é»˜è®¤auto_save"}),
                "instruction": ("STRING", {"multiline": True, "default": "æè¿°è¾“å…¥å›¾åƒçš„å…³é”®ç‰¹å¾ï¼ˆé¢œè‰²ã€å½¢çŠ¶ã€å¤§å°ã€çº¹ç†ã€å¯¹è±¡ã€èƒŒæ™¯ï¼‰ï¼Œç„¶åè§£é‡Šç”¨æˆ·çš„æ–‡æœ¬æŒ‡ä»¤åº”å¦‚ä½•ä¿®æ”¹æˆ–æ”¹å˜å›¾åƒã€‚ç”Ÿæˆç¬¦åˆç”¨æˆ·è¦æ±‚çš„æ–°å›¾åƒï¼ŒåŒæ—¶åœ¨é€‚å½“çš„æƒ…å†µä¸‹ä¿æŒä¸åŸå§‹è¾“å…¥çš„ä¸€è‡´æ€§ã€‚", "placeholder": "ä¸å»ºè®®ä¿®æ”¹", "tooltip": "æŒ‡ä»¤ - ç³»ç»ŸæŒ‡ä»¤ï¼Œç”¨äºæŒ‡å¯¼å‚è€ƒå›¾åƒçš„å›¾åƒç¼–è¾‘"}),
            }
        }

    RETURN_TYPES = ("IMAGE", "LATENT", "IMAGE")
    RETURN_NAMES = ("ç”Ÿæˆå›¾åƒ", "ï¼ˆå¯é€‰ï¼‰Latent", "ç¼©æ”¾ååŸå›¾")
    FUNCTION = "sample"
    CATEGORY = "sampling"
    # æ³¨æ„è¯­è¨€æ–‡ä»¶ä¸­ä¸èƒ½ç”¨@ç¬¦å·
    DESCRIPTION = "NAKU ä¸“ç”¨ QWENé›†æˆé‡‡æ ·å™¨ - Ké‡‡æ ·å™¨ï¼Œæ™ºèƒ½å¤šæ¨¡æ€é‡‡æ ·å™¨ï¼Œæ”¯æŒæ–‡ç”Ÿå›¾/å›¾ç”Ÿå›¾åŒæ¨¡å¼ï¼Œä¼˜åŒ–å®˜æ–¹åç§»é—®é¢˜ï¼Œæ›´éµä»æŒ‡ä»¤ï¼Œå›¾ç‰‡ç¼©æ”¾ã€å¯å¤„ç†å¤šå¼ å‚è€ƒå›¾ã€è‡ªåŠ¨æ˜¾å­˜/å†…å­˜ç®¡ç†ã€æ‰¹é‡ç”Ÿæˆã€è‡ªåŠ¨ä¿å­˜ã€å£°éŸ³é€šçŸ¥ã€AuraFlowä¼˜åŒ–ã€CFGæ ‡å‡†åŒ–è°ƒèŠ‚ç­‰å…¨æ–¹ä½åŠŸèƒ½ï¼Œä¸éœ€è¦è¿é‚£ä¹ˆå¤šçº¿å•¦~~~~"


    


    def sample(self, model, clip, vae, positive_prompt, negative_prompt, generation_mode, batch_size, width, height, seed, steps, cfg, sampler_name, scheduler, denoise=1.0, image1=None, image2=None, image3=None, image4=None, image5=None, latent=None, controlnet_data=None, auraflow_shift=0, cfg_norm_strength=0, enable_clean_gpu_memory=False, enable_clean_cpu_memory_after_finish=False, enable_sound_notification=False, instruction="", auto_save_output_folder="", output_filename_prefix="auto_save"):


        # Print start execution information
        print(f"å¼€å§‹æ‰§è¡Œé‡‡æ ·ä»»åŠ¡......")
        print(f"ç§å­: {seed}")
        print(f"æ­¥éª¤æ•°: {steps}")
        print(f"CFGå¼ºåº¦: {cfg}")
        print(f"é™å™ªå¼ºåº¦: {denoise}")
        print(f"é‡‡æ ·å™¨: {sampler_name}")
        print(f"è°ƒåº¦å™¨: {scheduler}")
        print(f"åˆ†è¾¨ç‡: {width} x {height}")
        print(f"ç”Ÿæˆæ¨¡å¼: {generation_mode}")
        print(f"æ‰¹é‡å¤§å°: {batch_size}")
        print(f"AuraFlow Shift: {auraflow_shift}")
        print(f"CFGè§„èŒƒåŒ–å¼ºåº¦: {cfg_norm_strength}")
        print(f"æ­£å‘æç¤ºè¯é•¿åº¦: {len(positive_prompt)}")
        print(f"è´Ÿå‘æç¤ºè¯é•¿åº¦: {len(negative_prompt)}")
        print(f"æŒ‡ä»¤é•¿åº¦: {len(instruction)}")
        print(f"è‡ªåŠ¨ä¿å­˜æ–‡ä»¶å¤¹: {auto_save_output_folder if auto_save_output_folder else 'ç¦ç”¨'}")
        print(f"è¾“å‡ºæ–‡ä»¶åå‰ç¼€: {output_filename_prefix}")
        print(f"æ¸…ç†GPUå†…å­˜: {enable_clean_gpu_memory}")
        print(f"ç»“æŸåæ¸…ç†CPUå†…å­˜: {enable_clean_cpu_memory_after_finish}")
        print(f"å£°éŸ³é€šçŸ¥: {enable_sound_notification}")

        # Initialize scaled images
        image1_scaled = image1


        if auraflow_shift > 0:
            print(f"âœ¨ åº”ç”¨shiftå‚æ•°/Applying shift parameter: {auraflow_shift}")
            m = model.clone()
            import comfy.model_sampling
            sampling_base = comfy.model_sampling.ModelSamplingDiscreteFlow
            sampling_type = comfy.model_sampling.CONST
            class ModelSamplingAdvanced(sampling_base, sampling_type):
                pass
            model_sampling = ModelSamplingAdvanced(m.model.model_config)
            model_sampling.set_parameters(shift=auraflow_shift, multiplier=1.0)
            m.add_object_patch("model_sampling", model_sampling)
            model = m
            print("shiftå‚æ•°å·²åº”ç”¨æˆåŠŸ/Shift parameter applied successfully")

        if cfg_norm_strength > 0:
            print(f"åº”ç”¨å¼ºåº¦: {cfg_norm_strength}")
            m = model.clone()
            def cfg_norm(args):
                cond_p = args['cond_denoised']
                pred_text_ = args["denoised"]
                norm_full_cond = torch.norm(cond_p, dim=1, keepdim=True)
                norm_pred_text = torch.norm(pred_text_, dim=1, keepdim=True)
                scale = (norm_full_cond / (norm_pred_text + 1e-8)).clamp(min=0.0, max=1.0)
                return pred_text_ * scale * cfg_norm_strength
            m.set_model_sampler_post_cfg_function(cfg_norm)
            model = m
            print("è§„èŒƒåŒ–å·²åº”ç”¨æˆåŠŸ/Normalization applied successfully")




        

        if generation_mode == "å›¾åƒç¼–è¾‘æ¨¡å¼":

            if image1 is None:
                raise Exception("å›¾åƒç¼–è¾‘æ¨¡å¼å¿…é¡»è‡³å°‘è¾“å…¥ä¸€å¼ å›¾ç‰‡ï¼Œè¯·è¾“å…¥å›¾åƒ1ï¼ˆä¸»å›¾ï¼‰ã€‚")

            # Scale reference images if needed

            images_scaled = [image1, image2, image3, image4, image5]

            if width > 0 and height > 0:
                print(f"[å›¾åƒç¼©æ”¾] å°†å›¾åƒç¼©æ”¾è‡³ {width}x{height}")

                for i, img in enumerate(images_scaled):
                    if img is not None:
                        # try:
                            scaled_image, _, _, _, _ = image_scale_by_aspect_ratio('original', 1, 1, 'letterbox', 'lanczos', '8', 'max_size', (width, height), '#000000', img, None)
                            images_scaled[i] = scaled_image
                        # except Exception as e:
                        #  log(f"âš ï¸ [Image Scale] Cannot scale image {i+1} with shape {img.shape}: {e}")
                        #     images_scaled[i] = img
                    # else: None

                print("[å›¾åƒç¼©æ”¾] å›¾åƒç¼©æ”¾å®Œæˆ")

            image1_scaled, image2_scaled, image3_scaled, image4_scaled, image5_scaled = images_scaled

            image_prompt, images_vl, llama_template, ref_latents = get_image_prompt(vae, image1_scaled, image2_scaled, image3_scaled, image4_scaled, image5_scaled, upscale_method="lanczos", crop="disabled", instruction=instruction)

            print("â³ [æç¤ºè¯] æ­£åœ¨ç”Ÿæˆæ­£å‘æ¡ä»¶...")
            positive = prompt_encode(clip, positive_prompt, image_prompt=image_prompt, images_vl=images_vl, llama_template=llama_template, ref_latents=ref_latents)
            print("â³ [æç¤ºè¯] æ­£åœ¨ç”Ÿæˆè´Ÿå‘æ¡ä»¶...")
            negative = prompt_encode(clip, negative_prompt, image_prompt=image_prompt, images_vl=images_vl, llama_template=llama_template, ref_latents=ref_latents)
            print("[æç¤ºè¯] æç¤ºè¯æ¡ä»¶ç”Ÿæˆå®Œæˆ")


        else:
            if width > 0 and height > 0:
                positive = prompt_encode(clip, positive_prompt)
                negative = prompt_encode(clip, negative_prompt)
            else:
                raise Exception("æ–‡ç”Ÿå›¾å¿…é¡»è¾“å…¥å®½é«˜ã€‚")

        # Apply ControlNet if provided
        if controlnet_data is not None and len(controlnet_data) > 0:
            try:
                # é¢„å…ˆå¤„ç†æ‰€æœ‰controlnetæ•°æ®ä»¥é¿å…é‡å¤æ“ä½œ
                for c_idx, c_data in enumerate(controlnet_data):
                    control_net = c_data["control_net"]
                    control_type = c_data["control_type"]
                    control_image = c_data["image"]
                    control_mask = c_data["mask"]
                    control_strength = c_data["strength"]
                    control_start_percent = c_data["start_percent"]
                    control_end_percent = c_data["end_percent"]

                    print(f"åº”ç”¨ControlNet {control_type} å¼ºåº¦: {control_strength} (ç¬¬{c_idx+1}/{len(controlnet_data)}ä¸ª)")

                    if control_strength > 0:

                        # å›¾åƒç¼–è¾‘-å±€éƒ¨é‡ç»˜ æ—¶ä½¿ç”¨ç¼©æ”¾ä¸»å›¾
                        if generation_mode == "å›¾åƒç¼–è¾‘æ¨¡å¼":
                            if control_type.lower() == "repaint" or control_type.lower() == "inpaint" or control_type.lower() == "inpainting" or control_type == "é‡ç»˜" or control_type == "å±€éƒ¨é‡ç»˜":

                                if width > 0 and height > 0:
                                    scaled_control_image, scaled_control_mask, _, _, _ = image_scale_by_aspect_ratio('original', 1, 1, 'letterbox', 'lanczos', '8', 'max_size', (width, height), '#000000', control_image, control_mask)
                                    control_image = scaled_control_image
                                    control_mask = scaled_control_mask

                        extra_concat=[]

                        if control_net.concat_mask and control_mask is not None:
                            control_mask = 1.0 - control_mask.reshape((-1, 1, control_mask.shape[-2], control_mask.shape[-1]))
                            control_mask_apply = comfy.utils.common_upscale(control_mask, control_image.shape[2], control_image.shape[1], "bilinear", "center").round()
                            control_image = control_image * control_mask_apply.movedim(1, -1).repeat(1, 1, 1, control_image.shape[3])
                            extra_concat = [control_mask]
                            print(f"ControlNet {control_type}åº”ç”¨é®ç½©")

                        control_hint = control_image.movedim(-1,1)

                        # ä¸ºæ¯ä¸ªControlNetåˆ›å»ºç‹¬ç«‹çš„å¤„ç†æµç¨‹ï¼Œé¿å…ç´¯ç§¯å†…å­˜
                        cnets = {}

                        # åº”ç”¨ControlNetåˆ°æ­£å‘æ¡ä»¶
                        positive_c = []
                        for t in positive:
                            d = t[1].copy()
                            prev_cnet = d.get('control', None)
                            if prev_cnet in cnets:
                                c_net = cnets[prev_cnet]
                            else:
                                c_net = control_net.copy().set_cond_hint(control_hint, control_strength, (control_start_percent, control_end_percent), vae=vae, extra_concat=extra_concat)
                                c_net.set_previous_controlnet(prev_cnet)
                                cnets[prev_cnet] = c_net

                            d['control'] = c_net
                            d['control_apply_to_uncond'] = False
                            n = [t[0], d]
                            positive_c.append(n)

                        # åº”ç”¨ControlNetåˆ°è´Ÿå‘æ¡ä»¶
                        negative_c = []
                        for t in negative:
                            d = t[1].copy()
                            prev_cnet = d.get('control', None)
                            if prev_cnet in cnets:
                                c_net = cnets[prev_cnet]
                            else:
                                # å¯¹äºè´Ÿå‘æ¡ä»¶ï¼Œä½¿ç”¨ç›¸åŒçš„å·²ç¼“å­˜ControlNetå®ä¾‹
                                c_net = cnets.get(prev_cnet, control_net.copy()).set_cond_hint(control_hint, control_strength, (control_start_percent, control_end_percent), vae=vae, extra_concat=extra_concat)
                                c_net.set_previous_controlnet(prev_cnet)
                                cnets[prev_cnet] = c_net

                            d['control'] = c_net
                            d['control_apply_to_uncond'] = False
                            n = [t[0], d]
                            negative_c.append(n)

                        positive = positive_c
                        negative = negative_c

                        print(f"ControlNet {control_type}åº”ç”¨æˆåŠŸ")

                        # æ¸…ç†ä¸´æ—¶å˜é‡ä»¥é‡Šæ”¾å†…å­˜
                        del control_hint, cnets
                        if enable_clean_gpu_memory or c_idx < len(controlnet_data) - 1:  # åœ¨å¤„ç†å¤šä¸ªControlNetæ—¶ï¼Œæˆ–å¯ç”¨æ¸…ç†æ—¶ï¼Œéƒ½è¿›è¡Œæ¸…ç†
                            comfy.model_management.cleanup_models()
                            comfy.model_management.soft_empty_cache()
                            gc.collect()
                    else:
                        print(f"âš ï¸ ControlNet {control_type}å¼ºåº¦è®¾ç½®ä¸º0ï¼Œä¸åº”ç”¨ControlNet")

                # åœ¨æ‰€æœ‰ControlNetå¤„ç†å®Œæˆåè¿›è¡Œæœ€ç»ˆæ¸…ç†
                gc.collect()
                comfy.model_management.soft_empty_cache()
            except Exception as e:
                raise Exception(f"âš ï¸ [ControlNet] ControlNet åº”ç”¨å¤±è´¥: {e}")



        if latent is None:
            if generation_mode == "å›¾åƒç¼–è¾‘æ¨¡å¼" and image1_scaled is not None:
                samples = vae.encode(image1_scaled[:,:,:,:3])  # Use scaled image1 (image1_scaled), not original
                if batch_size > 1:
                    samples = samples.repeat((batch_size,) + ((1,) * (samples.ndim - 1)))
            else:
                samples = torch.zeros([batch_size, 4, height // 8, width // 8], device=self.device)
            latent = {"samples":samples}

        

        


        print("ğŸš€ å¼€å§‹é‡‡æ ·è¿‡ç¨‹...")
        print(f"æ€»æ­¥æ•°: {steps}")

        if enable_clean_gpu_memory:
            print("é¢„æ¸…ç†æ˜¾å­˜å ç”¨...")
            try:
                cleanGPUUsedForce()
                remove_cache('*')
            except ImportError:
                print("ğŸ”• æ˜¾å­˜æ¸…ç†å¤±è´¥")
            print("é¢„æ˜¾å­˜æ¸…ç†å®Œæˆ")
        else:
            # å³ä½¿æœªå¯ç”¨æ˜¾å¼æ¸…ç†ï¼Œä¹Ÿæ‰§è¡ŒåŸºæœ¬çš„å†…å­˜ç®¡ç†
            comfy.model_management.unload_all_models()
            comfy.model_management.soft_empty_cache()
            gc.collect()

        # åœ¨é‡‡æ ·å‰å†æ¬¡ç¡®ä¿æ¨¡å‹è¢«æ­£ç¡®åŠ è½½åˆ°é€‚å½“çš„è®¾å¤‡ä¸Š
        model = model.to(comfy.model_management.get_torch_device())

        latent_output = common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent, denoise=denoise)

        print("æ­£åœ¨è§£ç æ½œç©ºé—´...")
        output_images = vae.decode(latent_output["samples"])
        if len(output_images.shape) == 5: #Combine batches
            output_images = output_images.reshape(-1, output_images.shape[-3], output_images.shape[-2], output_images.shape[-1])
        print("è§£ç å®Œæˆ")

        # è§£ç åè¿›è¡Œæ˜¾å­˜æ¸…ç†
        if enable_clean_gpu_memory:
            comfy.model_management.cleanup_models()
            comfy.model_management.soft_empty_cache()
            gc.collect()



        if auto_save_output_folder:
            try:
                import folder_paths
                output_filename_prefix = output_filename_prefix or "auto_save"
                if os.path.isabs(auto_save_output_folder):
                    full_output_folder = auto_save_output_folder
                else:
                    output_dir = folder_paths.get_output_directory()
                    full_output_folder = os.path.join(output_dir, auto_save_output_folder)

                if not os.path.exists(full_output_folder):
                    os.makedirs(full_output_folder, exist_ok=True)

                print(f"ğŸ’¾ [Auto Save] è‡ªåŠ¨ä¿å­˜æ–‡ä»¶è‡³ ã€{full_output_folder}ã€‘")

                for batch_number, image in enumerate(output_images):
                    img = Image.fromarray((image.cpu().numpy() * 255).astype(np.uint8))
                    file = f"{output_filename_prefix}_{seed}_{batch_number:05}.png"
                    img.save(os.path.join(full_output_folder, file))

                print("[Auto Save] è‡ªåŠ¨ä¿å­˜æ–‡ä»¶æˆåŠŸ")
            except ImportError:
                print("ğŸ”• è‡ªåŠ¨ä¿å­˜æ–‡ä»¶å¤±è´¥")


        if enable_clean_gpu_memory:
            print("åæ¸…ç†æ˜¾å­˜å ç”¨...")
            try:
                cleanGPUUsedForce()
                remove_cache('*')
            except ImportError:
                print("ğŸ”• æ˜¾å­˜æ¸…ç†å¤±è´¥")
            print("åæ˜¾å­˜æ¸…ç†å®Œæˆ")

        if enable_clean_cpu_memory_after_finish:
            print("å®Œæˆåæ¸…ç†CPUå†…å­˜...")
            try:
                clean_ram(clean_file_cache=True, clean_processes=True, clean_dlls=True, retry_times=3)
            except Exception as e:
                print(f"ğŸ”• RAMæ¸…ç†å¤±è´¥: {str(e)}")
            else:
                print("[Clean CPU Memory After Finish] RAMæ¸…ç†å®Œæˆ")

        if enable_sound_notification:
            try:
                import winsound
                import time
                # æ’­æ”¾å¿«é€Ÿç´§å‡‘çš„æ—‹å¾‹ï¼šA4, C5, E5, G5, E5, G5ï¼Œè¾ƒçŸ­é—´éš”ä½¿æ—‹å¾‹è¿è´¯
                frequencies = [440, 523, 659, 784, 659, 784]
                for freq in frequencies:
                    winsound.Beep(freq, 150)
                    time.sleep(0.005)  # æ›´çŸ­é—´éš”åŠ å¿«èŠ‚å¥
                print("[å£°éŸ³é€šçŸ¥] å®Œæˆæ—‹å¾‹æ’­æ”¾")
            except ImportError:
                print("ğŸ”• [å£°éŸ³é€šçŸ¥] è¯¥ç³»ç»Ÿä¸æ”¯æŒå£°éŸ³é€šçŸ¥")
            except Exception as e:
                print(f"ğŸ”• [å£°éŸ³é€šçŸ¥] éŸ³é¢‘æ’­æ”¾å¤±è´¥: {str(e)}")

        return (output_images, latent_output, image1_scaled)
        


    def set_shift(self, model, sigma_shift):
        """è®¾ç½®AuraFlowæ¨¡å‹çš„shiftå‚æ•°"""
        import comfy.model_sampling

        model_sampling = model.get_model_object("model_sampling")
        if not model_sampling:
            sampling_base = comfy.model_sampling.ModelSamplingDiscreteFlow
            sampling_type = comfy.model_sampling.CONST
            class ModelSamplingAdvanced(sampling_base, sampling_type):
                pass
            model_sampling = ModelSamplingAdvanced(model.model.model_config)

        model_sampling.set_parameters(shift=sigma_shift / 1000.0 * 100, multiplier=1000)
        model.add_object_patch("model_sampling", model_sampling)
        return model

class ExtraOptions:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {

            }
        }

    RETURN_TYPES = ("EXTRA_OPTIONS",)
    RETURN_NAMES = ("é¢å¤–è®¾å®š",)
    FUNCTION = "get_options"
    CATEGORY = "sampling"
    DESCRIPTION = "é¢å¤–è®¾å®š - é«˜çº§å‚æ•°è®¾ç½®"

    def get_options(self):
        options = {

        }
        return (options,)

class QwenImageControlNetIntegratedLoader:
    @classmethod
    def INPUT_TYPES(s):
        type_options = ["auto"] + list(UNION_CONTROLNET_TYPES.keys())
        return {
            "required": {
                "image": ("IMAGE", {"tooltip": "æ§åˆ¶å›¾åƒ - ControlNet æ§åˆ¶å›¾åƒè¾“å…¥"}),
                "control_net_name": (folder_paths.get_filename_list("controlnet"), {"tooltip": "ControlNetæ¨¡å‹ - é€‰æ‹©è¦ä½¿ç”¨çš„ ControlNet æ¨¡å‹"}),
                "control_type": (type_options, {"default": "auto", "tooltip": "æ§åˆ¶ç±»å‹ - ControlNet çš„å…·ä½“æ§åˆ¶ç±»å‹ï¼Œå¦‚å§¿æ€ã€ è¾¹ç¼˜æ£€æµ‹ã€æ·±åº¦ç­‰"}),
                "strength": ("FLOAT", {"default": 2.0, "min": 0.0, "max": 10.0, "step": 0.01, "tooltip": "æ§åˆ¶å¼ºåº¦ - ControlNet å¯¹ç”Ÿæˆç»“æœçš„å½±å“å¼ºåº¦"}),
                "start_percent": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001, "tooltip": "æ§åˆ¶æ­¥æ•°å¼€å§‹ç™¾åˆ†æ¯” - ControlNet æ•ˆæœå¼€å§‹åº”ç”¨çš„æ­¥æ•°ç™¾åˆ†æ¯”"}),
                "end_percent": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001, "tooltip": "æ§åˆ¶æ­¥æ•°ç»“æŸç™¾åˆ†æ¯” - ControlNet æ•ˆæœç»“æŸåº”ç”¨çš„æ­¥æ•°ç™¾åˆ†æ¯”"}),
            },
            "optional": {
                "mask": ("MASK", {"tooltip": "é®ç½©ï¼ˆå¯é€‰ï¼‰ - Inpainting é®ç½©ï¼Œç”¨äº ControlNet åŒºåŸŸæ§åˆ¶"}),
                "controlnet_data": ("CONTROL_NET_DATA", {"tooltip": "ControlNet æ•°æ®ï¼ˆå¯é€‰ï¼‰ - è¾“å…¥ ControlNet é›†æˆåŠ è½½å™¨è¾“å‡ºçš„æ•°æ®åŒ…ï¼Œç›´æ¥åº”ç”¨ ControlNet æ§åˆ¶"}),
            }
        }

    RETURN_TYPES = ("CONTROL_NET_DATA",)
    RETURN_NAMES = ("ControlNet æ•°æ®",)
    FUNCTION = "load_controlnet"
    CATEGORY = "conditioning/controlnet"
    DESCRIPTION = "NAKU ä¸“ç”¨ QWEN-ControlNet é›†æˆåŠ è½½å™¨ - éœ€è¦ ControlNet æ—¶ä½¿ç”¨"

    def load_controlnet(self, image, control_net_name, control_type, strength, start_percent, end_percent, mask=None, controlnet_data=None):

        if strength > 0:
            if image is None:
                raise Exception("é”™è¯¯: ä½¿ç”¨ControlNetå¿…é¡»ä¼ å…¥æ§åˆ¶å›¾åƒã€‚")
            
        if control_type.lower() == "repaint" or control_type.lower() == "inpaint" or control_type.lower() == "inpainting" or control_type == "é‡ç»˜" or control_type == "å±€éƒ¨é‡ç»˜":
            if mask is None:
                raise Exception("é”™è¯¯: ä½¿ç”¨å±€éƒ¨é‡ç»˜ControlNetå¿…é¡»ä¼ å…¥æ§åˆ¶é®ç½©ã€‚")

        # åŠ è½½ ControlNet
        controlnet = comfy.controlnet.load_controlnet(folder_paths.get_full_path_or_raise("controlnet", control_net_name))

        if controlnet is None:
            raise RuntimeError("é”™è¯¯: æ§åˆ¶å™¨æ–‡ä»¶æ— æ•ˆï¼Œä¸åŒ…å«æœ‰æ•ˆçš„controlnetæ¨¡å‹ã€‚")

        # è®¾ç½®æ§åˆ¶ç±»å‹
        controlnet = controlnet.copy()
        type_number = UNION_CONTROLNET_TYPES.get(control_type, -1)
        if type_number >= 0:
            controlnet.set_extra_arg("control_type", [type_number])
        else:
            controlnet.set_extra_arg("control_type", [])

        if controlnet_data is not None and len(controlnet_data) > 0:
            control_net_data_list = controlnet_data
        else:
            control_net_data_list = []

        # åˆ›å»ºæ•°æ®å¯¹è±¡
        control_net_data = {
            "control_net": controlnet,
            "control_type": control_type,
            "image": image,
            "mask": mask,
            "strength": strength,
            "start_percent": start_percent,
            "end_percent": end_percent
        }

        control_net_data_list.append(control_net_data)

        return (control_net_data_list,)

NODE_CLASS_MAPPINGS = {
    "QwenImageIntegratedKSampler": QwenImageIntegratedKSampler,
    "QwenImageControlNetIntegratedLoader": QwenImageControlNetIntegratedLoader,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "QwenImageIntegratedKSampler": "NAKU ä¸“ç”¨ QWENé›†æˆé‡‡æ ·å™¨",
    "QwenImageControlNetIntegratedLoader": "NAKU ä¸“ç”¨ QWEN-ControlNeté›†æˆåŠ è½½å™¨",
}
